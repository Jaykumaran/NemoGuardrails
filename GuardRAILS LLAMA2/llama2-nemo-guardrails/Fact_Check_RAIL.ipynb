{"cells":[{"cell_type":"markdown","metadata":{"id":"IVx7IehIMxDG"},"source":["# Fact-Checking Guardrails\n","\n","This use case consists of asking the LLM to re-check whether the output is consistent with the context. In other words, ask the LLM if the response is true based on the documents retrieved from the knowledge base.\n","\n","This notebook is based on example **Grounding Rail** presented in Nemo Guardrails official [repo](https://github.com/NVIDIA/NeMo-Guardrails/tree/main/examples/grounding_rail). The chatbot will be asked several questions about a certain report, and we will use Guardrails to prevent it from answering facts that are not contained within the document. We will implement this rail using both OpenAI and Llama2 models.\n","\n","<div align=\"center\">\n","<img src=\"./docs/imgs/fact_checking_workflow.png\" width=\"600\"/>\n","</div>"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcIvXOxMM028","executionInfo":{"status":"ok","timestamp":1704468301040,"user_tz":-330,"elapsed":24083,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"c7cb4357-093e-441d-deab-b51f8d2beed8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/GuardRAILS LLAMA2/llama2-nemo-guardrails"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXcSuUvCM6BM","executionInfo":{"status":"ok","timestamp":1704468301040,"user_tz":-330,"elapsed":6,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"c48fc315-503a-4215-ad8e-6b1e016709f3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GuardRAILS LLAMA2/llama2-nemo-guardrails\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install python-dotenv\n","!pip install transformers==4.33.1 --upgrade\n","!pip install nemoguardrails --upgrade\n","!pip install langchain --upgrade\n","!pip install accelerate --upgrade\n","!pip install spacy --upgrade #Optional\n","!pip install datasets bitsandbytes einops  -Uqqq\n","!pip install python-dotenv"],"metadata":{"id":"lY7mDrY-NCTn","executionInfo":{"status":"ok","timestamp":1704468416085,"user_tz":-330,"elapsed":109592,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJN9_SHSMxDJ","executionInfo":{"status":"ok","timestamp":1704468036054,"user_tz":-330,"elapsed":9,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"49a2f548-c03c-4358-d024-a18c913a6854"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":5}],"source":["## Load environment\n","\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv()"]},{"cell_type":"markdown","metadata":{"id":"G2KN06J7MxDK"},"source":["# OpenAI"]},{"cell_type":"markdown","metadata":{"id":"_QrtClzuMxDL"},"source":["Load Guardrails configuration files located under `fact_check_config/openai` erasing the `fact_check.co` file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-HpXMjQIMxDL","outputId":"fc5e0f0f-52a0-4ed7-f75e-c21ce9cf3cbe"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/sofiaperez/anaconda3/envs/llms/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# from nemoguardrails import LLMRails, RailsConfig\n","\n","# # initialize rails config\n","# config = RailsConfig.from_path(\"./fact_check_config/openai\")\n","\n","# # create rails\n","# app = LLMRails(config, verbose=True)"]},{"cell_type":"markdown","metadata":{"id":"Ri8sB2tCMxDM"},"source":["When asked some questions about the document contained in the `fact_check_config/openai/kb` folder, it answers accurately:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKdEasEEMxDM","outputId":"01dc162d-a40f-4b1e-a99b-9aed166cba5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["According to the US Bureau of Labor Statistics, the unemployment rate in March 2023 was 3.5 percent.\n"]}],"source":["# history = [{\"role\": \"user\", \"content\": \"What was the unemployment rate in March 2023?\"}]\n","# bot_message = await app.generate_async(messages=history)\n","# print(bot_message['content'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3URgPsCWMxDM","outputId":"c2888edd-e41a-4e96-e0a2-c91e433d5d75"},"outputs":[{"name":"stdout","output_type":"stream","text":["According to the US Bureau of Labor Statistics, the unemployment rate for teenagers in March 2023 was 9.8 percent.\n"]}],"source":["# history.append(bot_message)\n","# history.append(\n","#     {\"role\": \"user\", \"content\": \"What was the unemployment rate for teenagers?\"}\n","# )\n","# bot_message = await app.generate_async(messages=history)\n","# print(bot_message['content'])"]},{"cell_type":"markdown","metadata":{"id":"6_hZNHPBMxDN"},"source":["When asked a question that is not covered by the document, it gives a false statement:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdhduQaeMxDN","outputId":"76a9f0fa-39e8-4ff3-c42b-9725e3af6bc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["According to the US Bureau of Labor Statistics, the unemployment rate for senior citizens in March 2023 was 4.7 percent.\n"]}],"source":["# history.append(bot_message)\n","# history.append(\n","#     {\"role\": \"user\", \"content\": \"What was the unemployment rate for senior citizens?\"}\n","# )\n","# bot_message = await app.generate_async(messages=history)\n","# print(bot_message['content'])\n"]},{"cell_type":"markdown","metadata":{"id":"AdNvxXdjMxDN"},"source":["## Adding the fact check rail\n","\n","By adding the `fact_check.co` file back in the configuration, we will prevent the chatbot from hallucinating facts."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSof2CnuMxDO"},"outputs":[],"source":["# # initialize rails config\n","# config = RailsConfig.from_path(\"./fact_check_config/openai\")\n","\n","# # create rails\n","# app = LLMRails(config, verbose=True)"]},{"cell_type":"markdown","metadata":{"id":"cpt1vwHQMxDO"},"source":["When asked some questions about the document contained in the `fact_check_config/openai/kb` folder, it answers accurately:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWwfyBVjMxDO","outputId":"d7193df6-167b-4a79-f1cd-b33c05da08da"},"outputs":[{"name":"stdout","output_type":"stream","text":["According to the March 2023 US jobs report, the unemployment rate in March 2023 was 3.5 percent.\n"]}],"source":["# history = [{\"role\": \"user\", \"content\": \"What was the unemployment rate in March 2023?\"}]\n","# bot_message = await app.generate_async(messages=history)\n","# print(bot_message['content'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymJsqzWQMxDO","outputId":"cb76cd17-5be6-4e4f-9b90-9e7c39179dce"},"outputs":[{"name":"stdout","output_type":"stream","text":["According to the March 2023 US jobs report, the unemployment rate for teenagers was 9.8 percent.\n"]}],"source":["# history.append(bot_message)\n","# history.append(\n","#     {\"role\": \"user\", \"content\": \"What was the unemployment rate for teenagers?\"}\n","# )\n","# bot_message = await app.generate_async(messages=history)\n","# print(bot_message['content'])"]},{"cell_type":"markdown","metadata":{"id":"4JRUOW4kMxDO"},"source":["When asked a question that is not covered by the document, it effectively replies that it is no enough information to answer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kufaArYMxDP","outputId":"34602806-e326-4c0e-8292-acdd393c9943"},"outputs":[{"name":"stdout","output_type":"stream","text":["I don't have enough information to answer\n"]}],"source":["# history.append(bot_message)\n","# history.append(\n","#     {\"role\": \"user\", \"content\": \"What was the unemployment rate for senior citizens?\"}\n","# )\n","# bot_message = await app.generate_async(messages=history)\n","# print(bot_message['content'])"]},{"cell_type":"markdown","metadata":{"id":"vzRaI4G1MxDP"},"source":["# Llama2"]},{"cell_type":"markdown","metadata":{"id":"zE5FwbnRMxDP"},"source":["Load the HuggingFace model and create a pipeline:"]},{"cell_type":"code","source":["# Important to be separated into different cell\n","import nest_asyncio\n","nest_asyncio.apply()\n","\n","# Useful for debugging\n","import logging\n","logging.basicConfig(level=logging.DEBUG)\n","\n","import accelerate\n","import bitsandbytes\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n"],"metadata":{"id":"a6j2yRFCNrMP","executionInfo":{"status":"ok","timestamp":1704469813207,"user_tz":-330,"elapsed":26187,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['HF_TOKEN'] = \"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\""],"metadata":{"id":"ogN9AEC3Ntok","executionInfo":{"status":"ok","timestamp":1704469813207,"user_tz":-330,"elapsed":3,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178,"referenced_widgets":["2282e2344362404f940e69e4ddd61a78","7120e29f355f4059b7455c5b22728ddf","c4e992b31dcb42879f4600513409c87d","64c5df261d5f4465b222f1b941761b61","6ea8e44139b647ddad2c6ad8522d59f3","f08953368b3d49c79dc6ec027ea53043","dbd598eb52ad4f649d71d94ffa02c8c4","6520cb72d5614b4c807dbf7530b3adb6","e32bc217cb1d49e68c3046f803b7aebc","ec450b9e073e463ab04edc17222b03d3","e8e5336fb7ee40ff9230b0f827a588c5"]},"id":"F3ibf_DKMxDP","executionInfo":{"status":"ok","timestamp":1704469892710,"user_tz":-330,"elapsed":79505,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"aa1972a3-7031-43ab-86e7-2eacdaac6f91"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2282e2344362404f940e69e4ddd61a78"}},"metadata":{}}],"source":["MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n","\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,            # load model in 4-bit precision\n","    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n","    bnb_4bit_use_double_quant=True, # Using double quantization as mentioned in QLoRA paper\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    # During computation, pre-trained model should be loaded in BF16 format\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    quantization_config = bnb_config,\n","    device_map = 'auto',\n","    use_cache=True,\n","    trust_remote_code=True,\n","#     use_flash_attention_2 = True\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    max_length=4096,\n","    do_sample=True,\n","    temperature=0.2,\n","    top_p=0.95,\n","    logprobs=None,\n","    top_k=40,\n","    repetition_penalty=1.1\n",")"]},{"cell_type":"markdown","metadata":{"id":"DyGFAHY7MxDP"},"source":["Wrap the pipeline using Langchain HuggingFacePipeline class. Then wrap it again using Nemo’s get_llm_instance_wrapper function and register it using register_llm_provider."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"cXA7A7SDMxDQ","executionInfo":{"status":"ok","timestamp":1704472185425,"user_tz":-330,"elapsed":804,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"outputs":[],"source":["from nemoguardrails.llm.helpers import get_llm_instance_wrapper\n","from nemoguardrails import LLMRails, RailsConfig\n","\n","from nemoguardrails.llm.providers import (\n","    HuggingFacePipelineCompatible,\n","    register_llm_provider,\n",")\n","\n","hf_llm = HuggingFacePipelineCompatible(pipeline=pipe)\n","provider = get_llm_instance_wrapper(\n","    llm_instance=hf_llm, llm_type=\"hf_pipeline_llama2\"\n",")\n","register_llm_provider(\"hf_pipeline_llama2\", provider)"]},{"cell_type":"markdown","metadata":{"id":"KLeZMqa5MxDQ"},"source":["Load Guardrails configuration files located under `fact_check_config/llama2` erasing the `fact_check.co` file."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"f7tunyv5MxDQ","executionInfo":{"status":"ok","timestamp":1704472201237,"user_tz":-330,"elapsed":2120,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"outputs":[],"source":["# initialize rails config\n","config = RailsConfig.from_path(\"/content/drive/MyDrive/GuardRAILS LLAMA2/llama2-nemo-guardrails/fact_check_config/llama2_step\")\n","\n","# create rails\n","app = LLMRails(config, verbose = True)"]},{"cell_type":"markdown","metadata":{"id":"NNESRZ8WMxDQ"},"source":["When asked some questions about the document contained in the `fact_check_config/llama2/kb` folder, it answers accurately:"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"i_CFvX8NMxDQ","executionInfo":{"status":"ok","timestamp":1704472224225,"user_tz":-330,"elapsed":22997,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"d4471351-8abd-49d8-8df0-41128bb47c86"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'The unemployment rate in March 2023 was 3.5%.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":42}],"source":["await app.generate_async(prompt=\"What was the unemployment rate in March 2023?\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"KlgFmPrhMxDR","executionInfo":{"status":"ok","timestamp":1704470340266,"user_tz":-330,"elapsed":25748,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"a9f3c8bb-2b87-4eb5-d85c-72f30279157c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'According to the latest data available, the unemployment rate for senior citizens (aged 55 and older) was 3.1% in March 2023.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}],"source":["await app.generate_async(prompt=\"What was the unemployment rate for senior citizens?\")"]},{"cell_type":"markdown","metadata":{"id":"P14-z95NMxDR"},"source":["## Adding the fact check rail"]},{"cell_type":"markdown","metadata":{"id":"_N07ndOLMxDR"},"source":["We add the `fact_check.co` file back in the configuration to prevent the chatbot from hallucinating facts."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"qCUksV3WMxDR","executionInfo":{"status":"ok","timestamp":1704472271351,"user_tz":-330,"elapsed":2799,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"outputs":[],"source":["from nemoguardrails import LLMRails, RailsConfig\n","\n","# initialize rails config\n","config = RailsConfig.from_path(\"/content/drive/MyDrive/GuardRAILS LLAMA2/llama2-nemo-guardrails/fact_check_config/llama2\")\n","\n","# create rails\n","app = LLMRails(config, verbose = True)"]},{"cell_type":"markdown","metadata":{"id":"_KvjjoUeMxDR"},"source":["When asked some questions about the document contained in the `fact_check_config/llama2/kb`, no answer is provided. Something is not working properly."]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"nE7Lx1RcMxDS","executionInfo":{"status":"ok","timestamp":1704472302162,"user_tz":-330,"elapsed":27911,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"f640ce3d-fe8e-47e2-e779-f1498c1adea9"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["\"I don't have enough information to answer\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}],"source":["await app.generate_async(prompt=\"What was the unemployment rate in March 2023?\")"]},{"cell_type":"markdown","metadata":{"id":"OMKlQmvLMxDS"},"source":["## Adding the fact check rail + few shot in prompt\n","\n","By adding some few shot examples to the prompt in the `general.yml` file located in the library `nemoguardrails/llm/prompts/` folder, the rail starts working."]},{"cell_type":"code","execution_count":47,"metadata":{"id":"5iFXrdv0MxDS","executionInfo":{"status":"ok","timestamp":1704472306153,"user_tz":-330,"elapsed":1307,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}}},"outputs":[],"source":["from nemoguardrails.llm.helpers import get_llm_instance_wrapper\n","from nemoguardrails import LLMRails, RailsConfig\n","\n","from nemoguardrails.llm.providers import (\n","    HuggingFacePipelineCompatible,\n","    register_llm_provider,\n",")\n","\n","hf_llm = HuggingFacePipelineCompatible(pipeline=pipe)\n","provider = get_llm_instance_wrapper(\n","    llm_instance=hf_llm, llm_type=\"hf_pipeline_llama2\"\n",")\n","register_llm_provider(\"hf_pipeline_llama2\", provider)\n","\n","# initialize rails config\n","config = RailsConfig.from_path(\"/content/drive/MyDrive/GuardRAILS LLAMA2/llama2-nemo-guardrails/fact_check_config/llama2\")\n","\n","# create rails\n","app = LLMRails(config, verbose = True)"]},{"cell_type":"markdown","metadata":{"id":"KTbKv-ZeMxDS"},"source":["When asked a question that is not covered by the document, it effectively replies that it is no enough information to answer."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"D6JrySTFMxDS","executionInfo":{"status":"ok","timestamp":1704472335788,"user_tz":-330,"elapsed":26303,"user":{"displayName":"Jaykumaran R","userId":"17045730342647043745"}},"outputId":"897d9cf8-c9a1-4659-91b7-e230897df058"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","WARNING:nemoguardrails.llm.params:Parameter temperature does not exist for WrapperLLM\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["\"I don't have enough information to answer\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}],"source":["await app.generate_async(prompt=\"What was the unemployment rate for senior citizens?\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2282e2344362404f940e69e4ddd61a78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7120e29f355f4059b7455c5b22728ddf","IPY_MODEL_c4e992b31dcb42879f4600513409c87d","IPY_MODEL_64c5df261d5f4465b222f1b941761b61"],"layout":"IPY_MODEL_6ea8e44139b647ddad2c6ad8522d59f3"}},"7120e29f355f4059b7455c5b22728ddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f08953368b3d49c79dc6ec027ea53043","placeholder":"​","style":"IPY_MODEL_dbd598eb52ad4f649d71d94ffa02c8c4","value":"Loading checkpoint shards: 100%"}},"c4e992b31dcb42879f4600513409c87d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6520cb72d5614b4c807dbf7530b3adb6","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e32bc217cb1d49e68c3046f803b7aebc","value":2}},"64c5df261d5f4465b222f1b941761b61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec450b9e073e463ab04edc17222b03d3","placeholder":"​","style":"IPY_MODEL_e8e5336fb7ee40ff9230b0f827a588c5","value":" 2/2 [01:04&lt;00:00, 29.50s/it]"}},"6ea8e44139b647ddad2c6ad8522d59f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f08953368b3d49c79dc6ec027ea53043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd598eb52ad4f649d71d94ffa02c8c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6520cb72d5614b4c807dbf7530b3adb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32bc217cb1d49e68c3046f803b7aebc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec450b9e073e463ab04edc17222b03d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8e5336fb7ee40ff9230b0f827a588c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}